{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Comenzaremos con un modelo baseline para luego poder comparar la performance de modelos más complejos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.81)\n",
      "Requirement already satisfied: numpy in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from xgboost) (1.15.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from xgboost) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from lightgbm) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from lightgbm) (1.15.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy.stats as st\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import r2_score, median_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>view</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>lat</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>renovated</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>condition</th>\n",
       "      <th>long</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>house_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7129300520</th>\n",
       "      <td>221900</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>1340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5650</td>\n",
       "      <td>5650</td>\n",
       "      <td>1955</td>\n",
       "      <td>3</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>98178</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414100192</th>\n",
       "      <td>538000</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>1690</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7242</td>\n",
       "      <td>7639</td>\n",
       "      <td>1951</td>\n",
       "      <td>3</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>98125</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631500400</th>\n",
       "      <td>180000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>2720</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>8062</td>\n",
       "      <td>1933</td>\n",
       "      <td>3</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>98028</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487200875</th>\n",
       "      <td>604000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>1360</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>910</td>\n",
       "      <td>4</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>1965</td>\n",
       "      <td>5</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>98136</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954400510</th>\n",
       "      <td>510000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>1800</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8080</td>\n",
       "      <td>7503</td>\n",
       "      <td>1987</td>\n",
       "      <td>3</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>98074</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             price  sqft_living  grade  sqft_above  sqft_living15  bathrooms  \\\n",
       "7129300520  221900         1180      7        1180           1340          1   \n",
       "6414100192  538000         2570      7        2170           1690          2   \n",
       "5631500400  180000          770      6         770           2720          1   \n",
       "2487200875  604000         1960      7        1050           1360          3   \n",
       "1954400510  510000         1680      8        1680           1800          2   \n",
       "\n",
       "            view  sqft_basement  bedrooms      lat  waterfront  floors  \\\n",
       "7129300520     0              0         3  47.5112           0       1   \n",
       "6414100192     0            400         3  47.7210           0       2   \n",
       "5631500400     0              0         2  47.7379           0       1   \n",
       "2487200875     0            910         4  47.5208           0       1   \n",
       "1954400510     0              0         3  47.6168           0       1   \n",
       "\n",
       "            renovated  sqft_lot  sqft_lot15  yr_built  condition     long  \\\n",
       "7129300520          0      5650        5650      1955          3 -122.257   \n",
       "6414100192          1      7242        7639      1951          3 -122.319   \n",
       "5631500400          0     10000        8062      1933          3 -122.233   \n",
       "2487200875          0      5000        5000      1965          5 -122.393   \n",
       "1954400510          0      8080        7503      1987          3 -122.045   \n",
       "\n",
       "            zipcode  house_age  \n",
       "7129300520    98178         59  \n",
       "6414100192    98125         63  \n",
       "5631500400    98028         82  \n",
       "2487200875    98136         49  \n",
       "1954400510    98074         28  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/kc_house_data_clean_with_outliers.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "X = df.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split (X, y, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: 0.698482 (0.013185)\n",
      "ScaledLASSO: 0.697675 (0.012840)\n",
      "ScaledEN: 0.670505 (0.013958)\n",
      "ScaledKNN: 0.785186 (0.027530)\n",
      "ScaledCART: 0.733370 (0.068837)\n",
      "ScaledGBM: 0.865226 (0.020624)\n",
      "ScaledRFR: 0.854956 (0.031478)\n",
      "ScaledBR: 0.854384 (0.025137)\n",
      "ScaledABR: 0.091177 (0.092352)\n",
      "ScaledETR: 0.857879 (0.023101)\n",
      "ScaledXGB: 0.864449 (0.016561)\n",
      "ScaledLGBM: 0.878307 (0.018618)\n"
     ]
    }
   ],
   "source": [
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))\n",
    "pipelines.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingRegressor())])))\n",
    "pipelines.append(('ScaledRFR', Pipeline([('Scaler', StandardScaler()),('RFR', RandomForestRegressor())])))\n",
    "pipelines.append(('ScaledBR', Pipeline([('Scaler', StandardScaler()),('BR', BaggingRegressor())])))\n",
    "pipelines.append(('ScaledABR', Pipeline([('Scaler', StandardScaler()),('ABR', AdaBoostRegressor())])))\n",
    "pipelines.append(('ScaledETR', Pipeline([('Scaler', StandardScaler()),('ETR', ExtraTreesRegressor())])))\n",
    "pipelines.append(('ScaledXGB', Pipeline([('Scaler', StandardScaler()),('XGB', XGBRegressor())])))\n",
    "pipelines.append(('ScaledLGBM', Pipeline([('Scaler', StandardScaler()),('LGBM', LGBMRegressor())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, random_state=21)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='r2')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Notas:**\n",
    "Podemos observar que `GradientBoostingRegressor`, `XGBRegressor`, y `LGBMRegressor` fueron los que mejor que nos dieron. Seguiremos explotando estos modelos utilizando gridsearch o randomsearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Gridsearch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Partiendo del siguiente conjunto de parametros comenzaremos a buscar los mejores para poder mejorar los modelos seleccionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "one_to_left = st.beta(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {  \n",
    "    \"n_estimators\": np.array([100,200,300,400, 500, 600]), # Number of boosted trees to fit.\n",
    "    \"max_depth\": st.randint(3, 12),     # Maximum tree depth for base learners.\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4), #     Boosting learning rate (xgb’s “eta”)\n",
    "    \"subsample\": one_to_left     # Subsample ratio of the training instance.  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### GrandientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed: 42.8min\n",
      "[Parallel(n_jobs=2)]: Done 250 out of 250 | elapsed: 54.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=21, shuffle=False),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_sampl...te=21, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=25, n_jobs=2,\n",
       "          param_distributions={'n_estimators': array([ 50, 100, 200, 300, 400]), 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D3D9DE76A0>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D3D9DE7390>, 'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D3D9DE7DD8>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='r2', verbose=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=21)\n",
    "kfold = KFold(n_splits=10, random_state=21)\n",
    "grid_gbr = RandomizedSearchCV(gbr, params, n_iter=25, verbose= True, scoring='r2', cv=kfold, n_jobs=2)\n",
    "grid_gbr.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_predict_gbr = grid_gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### XGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed: 73.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=21, shuffle=False),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=25, n_jobs=None,\n",
       "          param_distributions={'n_estimators': array([100, 200, 300, 400, 500, 600]), 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D3D9F1B128>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D3D9F1BF60>, 'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D3D9DE7DD8>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='r2', verbose=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "kfold = KFold(n_splits=10, random_state=21)\n",
    "grid_xgb = RandomizedSearchCV(xgb, params, n_iter=25, verbose= True, scoring='r2', cv=kfold)\n",
    "grid_xgb.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_predict_xgb = grid_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 25 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=21, shuffle=False),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "          fit_params=None, iid='warn', n_iter=25, n_jobs=None,\n",
       "          param_distributions={'n_estimators': array([ 50, 100, 200, 300, 400]), 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D3D9DE76A0>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D3D9DE7390>, 'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001D3D9DE7DD8>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='r2', verbose=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMRegressor()\n",
    "kfold = KFold(n_splits=10, random_state=21)\n",
    "grid_lgbm = RandomizedSearchCV(lgbm, params, n_iter=25, verbose= True, scoring='r2', cv=kfold)\n",
    "grid_lgbm.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_predict_lgbm = grid_lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best GradientBoosting: 0.892048 using {'learning_rate': 0.07373478151180804, 'max_depth': 4, 'n_estimators': 300, 'subsample': 0.8827027814384301}\n",
      "GradientBoosting Regressor R2-test_score: 0.8771\n",
      "MSE_test of GradientBoosting Regressor: 42175.71550105224 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Best XGB: 0.895153 using {'learning_rate': 0.20499170570069686, 'max_depth': 4, 'n_estimators': 400, 'subsample': 0.8856643553463572}\n",
      "XGB Regressor R2-test_score: 0.8884\n",
      "MSE_test of XGB Regressor: 39396.109375 \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Best LGBM: 0.886797 using {'learning_rate': 0.2028562929527566, 'max_depth': 4, 'n_estimators': 200, 'subsample': 0.7892862827539857}\n",
      "LGBM Regressor R2-test_score: 0.893\n",
      "MSE_test of LGBM Regressor: 40860.18255985374 \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Best GradientBoosting: %f using %s\" % (grid_gbr.best_score_, grid_gbr.best_params_))\n",
    "print(\"GradientBoosting Regressor R2-test_score: {}\".format(round(r2_score(y_predict_gbr, Y_test),4)))\n",
    "print(\"MSE_test of GradientBoosting Regressor: {} \".format(median_absolute_error(y_predict_gbr, Y_test)))\n",
    "print('-'*100)\n",
    "print(\"Best XGB: %f using %s\" % (grid_xgb.best_score_, grid_xgb.best_params_))\n",
    "print(\"XGB Regressor R2-test_score: {}\".format(round(r2_score(y_predict_xgb, Y_test),4)))\n",
    "print(\"MSE_test of XGB Regressor: {} \".format(median_absolute_error(y_predict_xgb, Y_test)))\n",
    "print('-'*100)\n",
    "print(\"Best LGBM: %f using %s\" % (grid_lgbm.best_score_, grid_lgbm.best_params_))\n",
    "print(\"LGBM Regressor R2-test_score: {}\".format(round(r2_score(y_predict_lgbm, Y_test),4)))\n",
    "print(\"MSE_test of LGBM Regressor: {} \".format(median_absolute_error(y_predict_lgbm, Y_test)))\n",
    "print('-'*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
