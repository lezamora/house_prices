{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Comenzaremos con un modelo baseline para luego poder comparar la performance de modelos m√°s complejos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.81)\n",
      "Requirement already satisfied: numpy in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from xgboost) (1.15.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from xgboost) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from lightgbm) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from lightgbm) (1.15.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lzamora\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from lightgbm) (0.19.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy.stats as st\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>view</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>lat</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>renovated</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>condition</th>\n",
       "      <th>long</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>house_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7129300520</th>\n",
       "      <td>221900</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>1340</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5650</td>\n",
       "      <td>5650</td>\n",
       "      <td>1955</td>\n",
       "      <td>3</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>98178</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414100192</th>\n",
       "      <td>538000</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>1690</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7242</td>\n",
       "      <td>7639</td>\n",
       "      <td>1951</td>\n",
       "      <td>3</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>98125</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631500400</th>\n",
       "      <td>180000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>2720</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>8062</td>\n",
       "      <td>1933</td>\n",
       "      <td>3</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>98028</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487200875</th>\n",
       "      <td>604000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>1360</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>910</td>\n",
       "      <td>4</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>1965</td>\n",
       "      <td>5</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>98136</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954400510</th>\n",
       "      <td>510000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>1800</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8080</td>\n",
       "      <td>7503</td>\n",
       "      <td>1987</td>\n",
       "      <td>3</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>98074</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             price  sqft_living  grade  sqft_above  sqft_living15  bathrooms  \\\n",
       "7129300520  221900         1180      7        1180           1340          1   \n",
       "6414100192  538000         2570      7        2170           1690          2   \n",
       "5631500400  180000          770      6         770           2720          1   \n",
       "2487200875  604000         1960      7        1050           1360          3   \n",
       "1954400510  510000         1680      8        1680           1800          2   \n",
       "\n",
       "            view  sqft_basement  bedrooms      lat  waterfront  floors  \\\n",
       "7129300520     0              0         3  47.5112           0       1   \n",
       "6414100192     0            400         3  47.7210           0       2   \n",
       "5631500400     0              0         2  47.7379           0       1   \n",
       "2487200875     0            910         4  47.5208           0       1   \n",
       "1954400510     0              0         3  47.6168           0       1   \n",
       "\n",
       "            renovated  sqft_lot  sqft_lot15  yr_built  condition     long  \\\n",
       "7129300520          0      5650        5650      1955          3 -122.257   \n",
       "6414100192          1      7242        7639      1951          3 -122.319   \n",
       "5631500400          0     10000        8062      1933          3 -122.233   \n",
       "2487200875          0      5000        5000      1965          5 -122.393   \n",
       "1954400510          0      8080        7503      1987          3 -122.045   \n",
       "\n",
       "            zipcode  house_age  \n",
       "7129300520    98178         59  \n",
       "6414100192    98125         63  \n",
       "5631500400    98028         82  \n",
       "2487200875    98136         49  \n",
       "1954400510    98074         28  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/kc_house_data_clean_with_outliers.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "X = df.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split (X, y, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: 0.698483 (0.013186)\n",
      "ScaledLASSO: 0.697675 (0.012840)\n",
      "ScaledEN: 0.670505 (0.013958)\n",
      "ScaledKNN: 0.785186 (0.027530)\n",
      "ScaledCART: 0.736964 (0.074525)\n",
      "ScaledGBM: 0.865678 (0.018842)\n",
      "ScaledRFR: 0.855258 (0.030266)\n",
      "ScaledBR: 0.856119 (0.016727)\n",
      "ScaledABR: 0.162461 (0.174244)\n",
      "ScaledETR: 0.855115 (0.026883)\n",
      "ScaledXGB: 0.864449 (0.016561)\n",
      "ScaledLGBM: 0.878307 (0.018618)\n"
     ]
    }
   ],
   "source": [
    "pipelines = []\n",
    "pipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()),('LR',LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()),('LASSO', Lasso())])))\n",
    "pipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()),('EN', ElasticNet())])))\n",
    "pipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()),('KNN', KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()),('CART', DecisionTreeRegressor())])))\n",
    "pipelines.append(('ScaledGBM', Pipeline([('Scaler', StandardScaler()),('GBM', GradientBoostingRegressor())])))\n",
    "pipelines.append(('ScaledRFR', Pipeline([('Scaler', StandardScaler()),('RFR', RandomForestRegressor())])))\n",
    "pipelines.append(('ScaledBR', Pipeline([('Scaler', StandardScaler()),('BR', BaggingRegressor())])))\n",
    "pipelines.append(('ScaledABR', Pipeline([('Scaler', StandardScaler()),('ABR', AdaBoostRegressor())])))\n",
    "pipelines.append(('ScaledETR', Pipeline([('Scaler', StandardScaler()),('ETR', ExtraTreesRegressor())])))\n",
    "pipelines.append(('ScaledXGB', Pipeline([('Scaler', StandardScaler()),('XGB', XGBRegressor())])))\n",
    "pipelines.append(('ScaledLGBM', Pipeline([('Scaler', StandardScaler()),('LGBM', LGBMRegressor())])))\n",
    "results = []\n",
    "names = []\n",
    "r_scuared = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, random_state=21)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='r2')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notas:**\n",
    "Podemos observar que `GradientBoostingRegressor`, `XGBRegressor`, y `LGBMRegressor` fueron los que mejor que nos dieron. Seguiremos explotando estos modelos utilizando gridsearch o randomsearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partiendo del siguiente conjunto de parametros comenzaremos a buscar los mejores para mejorar los modelos seleccionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_to_left = st.beta(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {  \n",
    "    \"n_estimators\": np.array([50,100,200,300,400]), # Number of boosted trees to fit.\n",
    "    \"max_depth\": st.randint(3, 12),     # Maximum tree depth for base learners.\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4), #     Boosting learning rate (xgb‚Äôs ‚Äúeta‚Äù)\n",
    "    \"colsample_bytree\": one_to_left, #     Subsample ratio of columns when constructing each tree.\n",
    "    \"subsample\": one_to_left,     # Subsample ratio of the training instance.\n",
    "    \"gamma\": st.uniform(0, 10), #     Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "    'reg_alpha': st.uniform(0.05,10),   # L1 regularization term on weights\n",
    "    \"min_child_weight\": st.uniform(1,20), #    Minimum sum of instance weight(hessian) needed in a child.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=21)\n",
    "kfold = KFold(n_splits=10, random_state=21)\n",
    "grid = RandomizedSearchCV(model_xg, params, n_iter=25, verbose= True, scoring='r2', cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
